{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c9fb4ac",
   "metadata": {},
   "source": [
    "**Checking for data completeness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e70cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9302ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_availability = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5617c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_column = 'pm1_0_atm'\n",
    "b_column = a_column + '_b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e416273",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Total available\n",
    "import os\n",
    "step = '1'\n",
    "\n",
    "data_availability[step] = {\"Description\" : \"Delete Missing data (Missing value from both channels)\"}\n",
    "\n",
    "dir = 'merged'\n",
    "files = [f for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))]\n",
    "for file in files:\n",
    "    file_path = os.path.join(dir, file)\n",
    "    df = pd.read_csv(file_path, parse_dates=['BDDateTime'])\n",
    "    total_sec = (pd.to_datetime(\"2025-06-30\", format = \"%Y-%m-%d\") - pd.to_datetime(\"2023-07-01\", format = \"%Y-%m-%d\")).total_seconds()\n",
    "    expected_data = total_sec / 120\n",
    "    available_data = df[~df[a_column].isna() | ~df[b_column].isna()].shape[0]\n",
    "    availability = (available_data / expected_data) * 100 if expected_data > 0 else 0\n",
    "    print(f\"File: {file}, Data Availability: {availability:.2f}%\")\n",
    "    data_availability[step][f'{file}'] = availability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6296e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One channel observation\n",
    "import os\n",
    "step = '2'\n",
    "data_availability[step] = {\"Description\" : \"Delete observation with data from one channel\"}\n",
    "\n",
    "dir = 'merged'\n",
    "files = [f for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))]\n",
    "for file in files:\n",
    "    file_path = os.path.join(dir, file)\n",
    "    df = pd.read_csv(file_path, parse_dates=['BDDateTime'])\n",
    "    total_sec = (pd.to_datetime(\"2025-06-30\", format = \"%Y-%m-%d\") - pd.to_datetime(\"2023-07-01\", format = \"%Y-%m-%d\")).total_seconds()\n",
    "    expected_data = total_sec / 120\n",
    "    available_data = df[~df[a_column].isna() & ~df[b_column].isna()].shape[0]\n",
    "    availability = (available_data / expected_data) * 100 if expected_data > 0 else 0\n",
    "    print(f\"File: {file}, Data Availability: {availability:.2f}%\")\n",
    "    data_availability[step][f'{file}'] = availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb9b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data with abnormal temperature and relative humidity\n",
    "import os\n",
    "step = '3'\n",
    "data_availability[step] = {\"Description\" : \"Delete observation with abnormal temperature and relative humidity (T<-200 or >1000 F, RH >100% or <0%)\"}\n",
    "\n",
    "dir = 'merged'\n",
    "files = [f for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))]\n",
    "for file in files:\n",
    "    file_path = os.path.join(dir, file)\n",
    "    df = pd.read_csv(file_path, parse_dates=['BDDateTime'])\n",
    "    total_sec = (pd.to_datetime(\"2025-06-30\", format = \"%Y-%m-%d\") - pd.to_datetime(\"2023-07-01\", format = \"%Y-%m-%d\")).total_seconds()\n",
    "    expected_data = total_sec / 120\n",
    "\n",
    "    #logics\n",
    "    pm_logic = ~df[a_column].isna() & ~df[b_column].isna()\n",
    "    rh_logic = (df['current_humidity'] < 100) & (df['current_humidity'] > 0)\n",
    "    temp_logic = (df['current_temp_f'] > -200) & (df['current_temp_f'] < 1000)\n",
    "    validity_logic = pm_logic & rh_logic & temp_logic\n",
    "\n",
    "    #avialability check\n",
    "    available_data = df[validity_logic].shape[0]\n",
    "    availability = (available_data / expected_data) * 100 if expected_data > 0 else 0\n",
    "    print(f\"File: {file}, Data Availability: {availability:.2f}%\")\n",
    "    data_availability[step][f'{file}'] = availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e29c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete data if pm2.5 < 100 um/m3 and delta > 10 um/m3, or if pm2.5 > 100um/m3  and delta > 10%\n",
    "import os\n",
    "step = '4a'\n",
    "data_availability[step] = {\"Description\" : \"Delete data if pm2.5 < 100 um/m3 and delta > 10 um/m3, or if pm2.5 > 100um/m3  and delta > 10%\"}\n",
    "\n",
    "dir = 'merged'\n",
    "files = [f for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))]\n",
    "for file in files:\n",
    "    file_path = os.path.join(dir, file)\n",
    "    df = pd.read_csv(file_path, parse_dates=['BDDateTime'])\n",
    "    total_sec = (pd.to_datetime(\"2025-06-30\", format = \"%Y-%m-%d\") - pd.to_datetime(\"2023-07-01\", format = \"%Y-%m-%d\")).total_seconds()\n",
    "    expected_data = total_sec / 120\n",
    "\n",
    "    #logics\n",
    "    pm_logic = ~df[a_column].isna() & ~df[b_column].isna()\n",
    "    rh_logic = (df['current_humidity'] < 100) & (df['current_humidity'] > 0)\n",
    "    temp_logic = (df['current_temp_f'] > -200) & (df['current_temp_f'] < 1000)\n",
    "    delta = (df[a_column] - df[b_column]).abs()\n",
    "    average = (df[a_column] + df[b_column])/2\n",
    "    cond1 = (delta <= 10) & (average <= 100)\n",
    "    cond2 = (delta <= 0.1*average) & (average > 100)\n",
    "    pm_channel_merge_logic = cond1 | cond2\n",
    "    validity_logic = pm_logic & rh_logic & temp_logic & pm_channel_merge_logic\n",
    "\n",
    "    #avialability check\n",
    "    available_data = df[validity_logic].shape[0]\n",
    "    availability = (available_data / expected_data) * 100 if expected_data > 0 else 0\n",
    "    print(f\"File: {file}, Data Availability: {availability:.2f}%\")\n",
    "    data_availability[step][f'{file}'] = availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae14cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete data delta > 5ug/m3 and delta > 61% a\n",
    "import os\n",
    "step = '4b'\n",
    "data_availability[step] = {\"Description\" : \"Delete data delta > 5ug/m3 and delta > 61% a\"}\n",
    "\n",
    "dir = 'merged'\n",
    "files = [f for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))]\n",
    "for file in files:\n",
    "    file_path = os.path.join(dir, file)\n",
    "    df = pd.read_csv(file_path, parse_dates=['BDDateTime'])\n",
    "    total_sec = (pd.to_datetime(\"2025-06-30\", format = \"%Y-%m-%d\") - pd.to_datetime(\"2023-07-01\", format = \"%Y-%m-%d\")).total_seconds()\n",
    "    expected_data = total_sec / 120\n",
    "\n",
    "    #logics\n",
    "    pm_logic = ~df[a_column].isna() & ~df[b_column].isna()\n",
    "    rh_logic = (df['current_humidity'] < 100) & (df['current_humidity'] > 0)\n",
    "    temp_logic = (df['current_temp_f'] > -200) & (df['current_temp_f'] < 1000)\n",
    "    delta = (df[a_column] - df[b_column]).abs()\n",
    "    average = (df[a_column] + df[b_column])/2\n",
    "    cond1 = (delta <= 10) & (average <= 100)\n",
    "    cond2 = (delta <= 0.1*average) & (average > 100)\n",
    "    pm_channel_merge_logic = cond1 | cond2\n",
    "    pm_channel_merge_logic2 = (delta < 5) | (delta < 0.61 * df[a_column])\n",
    "    validity_logic = pm_logic & rh_logic & temp_logic & pm_channel_merge_logic & pm_channel_merge_logic2\n",
    "\n",
    "    #avialability check\n",
    "    available_data = df[validity_logic].shape[0]\n",
    "    availability = (available_data / expected_data) * 100 if expected_data > 0 else 0\n",
    "    print(f\"File: {file}, Data Availability: {availability:.2f}%\")\n",
    "    data_availability[step][f'{file}'] = availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f3c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete data more than 500 ug/m3\n",
    "import os\n",
    "step = '5'\n",
    "data_availability[step] = {\"Description\" : \"Delete data with concentration more than 500 ug/m3 and with negative values\"}\n",
    "\n",
    "dir = 'merged'\n",
    "files = [f for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))]\n",
    "for file in files:\n",
    "    file_path = os.path.join(dir, file)\n",
    "    df = pd.read_csv(file_path, parse_dates=['BDDateTime'])\n",
    "    total_sec = (pd.to_datetime(\"2025-06-30\", format = \"%Y-%m-%d\") - pd.to_datetime(\"2023-07-01\", format = \"%Y-%m-%d\")).total_seconds()\n",
    "    expected_data = total_sec / 120\n",
    "\n",
    "    #logics\n",
    "    pm_logic = ~df[a_column].isna() & ~df[b_column].isna()\n",
    "    rh_logic = (df['current_humidity'] < 100) & (df['current_humidity'] > 0)\n",
    "    temp_logic = (df['current_temp_f'] > -200) & (df['current_temp_f'] < 1000)\n",
    "    delta = (df[a_column] - df[b_column]).abs()\n",
    "    average = (df[a_column] + df[b_column])/2\n",
    "    cond1 = (delta <= 10) & (average <= 100)\n",
    "    cond2 = (delta <= 0.1*average) & (average > 100)\n",
    "    pm_channel_merge_logic = cond1 | cond2\n",
    "    pm_channel_merge_logic2 = (delta < 5) | (delta < 0.61 * df[a_column])\n",
    "    data_range_logic = (df[a_column] >= 0) & (df[a_column] <= 500) & (df[b_column] >= 0) & (df[b_column] <= 500)\n",
    "    validity_logic = pm_logic & rh_logic & temp_logic & pm_channel_merge_logic & pm_channel_merge_logic2 & data_range_logic\n",
    "\n",
    "    #avialability check\n",
    "    available_data = df[validity_logic].shape[0]\n",
    "    availability = (available_data / expected_data) * 100 if expected_data > 0 else 0\n",
    "    print(f\"File: {file}, Data Availability: {availability:.2f}%\")\n",
    "    data_availability[step][f'{file}'] = availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a0faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "availability_df = pd.DataFrame.from_dict(data_availability, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c5cdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "availability_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077c4563",
   "metadata": {},
   "outputs": [],
   "source": [
    "availability_df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c975d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "availability_df.to_csv(\"availability.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc63a3e3",
   "metadata": {},
   "source": [
    "## Table a.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4733e2",
   "metadata": {},
   "source": [
    "##### Station wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d6e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_availability = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf64d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete data delta > 5ug/m3 and delta > 61% a\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "dir = 'hourly_averages'\n",
    "files = [f for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))]\n",
    "for file in files:\n",
    "    sensor = f'{file}'\n",
    "    hourly_availability[sensor] = {}\n",
    "    file_path = os.path.join(dir, file)\n",
    "    df = pd.read_csv(file_path, parse_dates=['time'])\n",
    "    total_sec = (pd.to_datetime(\"2025-06-30\", format = \"%Y-%m-%d\") - pd.to_datetime(\"2023-07-01\", format = \"%Y-%m-%d\")).total_seconds()\n",
    "    expected_data = total_sec / 3600\n",
    "\n",
    "    columns = ['pm1_0_atm', 'pm2_5_atm', 'pm10_0_atm']\n",
    "    hourly_availability[sensor] = {}\n",
    "    for column in columns:\n",
    "        #avialability check\n",
    "        available_data = df[df[column].notna()].shape[0]\n",
    "        availability = (available_data / expected_data) * 100 if expected_data > 0 else 0\n",
    "\n",
    "        pm_mean = df[column].mean()\n",
    "        pm_sd = df[column].std()\n",
    "        pm_gm = np.exp(np.mean(np.log(df[column].dropna().to_numpy())))\n",
    "        a = df[column].dropna().to_numpy()\n",
    "        pm_iqr = np.percentile(a, 75) - np.percentile(a, 25)\n",
    "\n",
    "        column_id = column.upper().replace('_ATM', '').replace('_', '.')\n",
    "\n",
    "        hourly_availability[sensor].update({\n",
    "            f'{column_id} Number of hours of data' : available_data,\n",
    "            f'{column_id} mean ± SD' : f\"{round(pm_mean, 2)} ± {round(pm_sd, 2)}\",\n",
    "            f'{column_id} GM' : pm_gm,\n",
    "            f'{column_id} IQR' : pm_iqr,\n",
    "            f'{column_id} Hourly data completeness' : availability\n",
    "        })\n",
    "\n",
    "    rh_mean = df['current_humidity'].mean()\n",
    "    rh_sd = df['current_humidity'].std()\n",
    "\n",
    "    temp_mean = df['current_temp_f'].mean()\n",
    "    temp_sd = df['current_temp_f'].std()\n",
    "    \n",
    "    hourly_availability[sensor].update({\n",
    "            'RH (mean ± sd)' : f\"{round(rh_mean, 2)} ± {round(rh_sd, 2)}\",\n",
    "            'Temp (mean ± sd)' : f\"{round(temp_mean, 2)} ± {round(temp_sd, 2)}\",\n",
    "    })\n",
    "\n",
    "    print(f\"File: {file}, Data Availability: {availability:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3007166",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_availability_df = pd.DataFrame.from_dict(hourly_availability, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_availability_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_availability_df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39866965",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_availability_df.to_csv(\"hourly_availability.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1de58a",
   "metadata": {},
   "source": [
    "##### zone wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d3d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_wise_hourly = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d74de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete data delta > 5ug/m3 and delta > 61% a\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "dir = 'hourly_averages'\n",
    "files = [f for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))]\n",
    "\n",
    "urban = ['U1.csv', 'U2.csv']\n",
    "suburb = ['SU1.csv', 'SU2.csv']\n",
    "rural = ['R1.csv', 'R2.csv', 'R3.csv', 'R4.csv']\n",
    "\n",
    "categories = [\n",
    "    (rural, \"Rural\", 1),\n",
    "    (suburb, \"Suburban\", 1), \n",
    "    (urban, \"Urban\", 3), \n",
    "    ]\n",
    "\n",
    "\n",
    "for category, cat_name, offset in categories:\n",
    "    zone_wise_hourly[cat_name] = {}\n",
    "    dfs = []\n",
    "    for file in category:\n",
    "        file_path = os.path.join(dir, file)\n",
    "        df = pd.read_csv(file_path, parse_dates=['time'])\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    total_sec = (pd.to_datetime(\"2025-06-30\", format = \"%Y-%m-%d\") - pd.to_datetime(\"2023-07-01\", format = \"%Y-%m-%d\")).total_seconds() * len(dfs)\n",
    "    expected_data = total_sec / 3600\n",
    "\n",
    "    columns = ['pm1_0_atm', 'pm2_5_atm', 'pm10_0_atm']\n",
    "    for column in columns:\n",
    "        #avialability check\n",
    "        available_data = df[df[column].notna()].shape[0]\n",
    "        availability = (available_data / expected_data) * 100 if expected_data > 0 else 0\n",
    "\n",
    "        pm_mean = df[column].mean()\n",
    "        pm_sd = df[column].std()\n",
    "        pm_gm = np.exp(np.mean(np.log(df[column].dropna().to_numpy())))\n",
    "        a = df[column].dropna().to_numpy()\n",
    "        pm_iqr = np.percentile(a, 75) - np.percentile(a, 25)\n",
    "\n",
    "        column_id = column.upper().replace('_ATM', '').replace('_', '.')\n",
    "\n",
    "        zone_wise_hourly[cat_name].update({\n",
    "            f'{column_id} Number of hours of data' : available_data,\n",
    "            f'{column_id} mean ± SD' : f\"{round(pm_mean, 2)} ± {round(pm_sd, 2)}\",\n",
    "            f'{column_id} GM' : pm_gm,\n",
    "            f'{column_id} IQR' : pm_iqr,\n",
    "            f'{column_id} Hourly data completeness' : availability\n",
    "        })\n",
    "\n",
    "    rh_mean = df['current_humidity'].mean()\n",
    "    rh_sd = df['current_humidity'].std()\n",
    "\n",
    "    temp_mean = df['current_temp_f'].mean()\n",
    "    temp_sd = df['current_temp_f'].std()\n",
    "    \n",
    "    zone_wise_hourly[cat_name].update({\n",
    "            'RH (mean ± sd)' : f\"{round(rh_mean, 2)} ± {round(rh_sd, 2)}\",\n",
    "            'Temp (mean ± sd)' : f\"{round(temp_mean, 2)} ± {round(temp_sd, 2)}\",\n",
    "    })\n",
    "\n",
    "    print(f\"File: {file}, Data Availability: {availability:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09098c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_wise_hourly_df = pd.DataFrame.from_dict(zone_wise_hourly, orient='index')\n",
    "zone_wise_hourly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e37720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_wise_hourly_df.to_clipboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python (pm)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
