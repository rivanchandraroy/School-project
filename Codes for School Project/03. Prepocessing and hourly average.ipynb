{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Date range correction\n",
    "* Only dates after July 2023 will be taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly average time shiftinhg\n",
    "dir = \"merged\"\n",
    "files = [d for d in os.listdir(dir) if d.endswith('.csv')]\n",
    "# subdirs = [\"Badda Home\"]\n",
    "for file in tqdm(files, desc=\"Processing homes\"):\n",
    "    print('='*50)\n",
    "    print(f\"Processing {file}\")\n",
    "    filedir = os.path.join(dir, file)\n",
    "    df = pd.read_csv(filedir, parse_dates=['UTCDateTime'])\n",
    "    df[\"BDDateTime\"] = df['UTCDateTime'] + pd.Timedelta(hours=6)\n",
    "    df.to_csv(filedir, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"merged\"\n",
    "files = [d for d in os.listdir(dir) if d.endswith('.csv')]\n",
    "# files = ['R4.csv']\n",
    "for file in files:\n",
    "    print('='*50)\n",
    "    print(f\"Processing {file}\")\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(dir, file), parse_dates=['BDDateTime'])\n",
    "    df = df[df['BDDateTime'] >= pd.to_datetime(\"2023-07-01\", format = \"%Y-%m-%d\")]\n",
    "    df = df[df['BDDateTime'] <= pd.to_datetime(\"2025-06-30\", format = \"%Y-%m-%d\")]\n",
    "    df.to_csv(os.path.join(dir, file), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merging channel\n",
    "\n",
    "# conditions =   {\n",
    "#     'R1' : 'avg',\n",
    "#     'R2' : 'b',\n",
    "#     'R3' : 'avg',\n",
    "#     'R4' : 'a',\n",
    "\n",
    "#     'SU1' : 'avg',\n",
    "#     'SU2' : 'avg',\n",
    "\n",
    "#     'U1' : 'avg',\n",
    "#     'U2' : 'a',\n",
    "#     'U3' : 'skip',\n",
    "#     'U4' : 'skip'\n",
    "# }\n",
    "\n",
    "conditions =   {\n",
    "    'R1' : 'avg',\n",
    "    'R2' : 'avg',\n",
    "    'R3' : 'avg',\n",
    "    'R4' : 'avg',\n",
    "\n",
    "    'SU1' : 'avg',\n",
    "    'SU2' : 'avg',\n",
    "\n",
    "    'U1' : 'avg',\n",
    "    'U2' : 'avg',\n",
    "    'U3' : 'skip',\n",
    "    'U4' : 'skip'\n",
    "}\n",
    "\n",
    "cols_to_combine = ['pm2_5_cf_1', 'pm2_5_atm', 'pm1_0_atm', 'pm10_0_atm']\n",
    "\n",
    "## average calculation\n",
    "dir = \"merged\"\n",
    "target = 'channel_combined'\n",
    "files = [d for d in os.listdir(dir) if d.endswith('csv')]\n",
    "for file in tqdm(files):\n",
    "    print(f'pricessing {file}')\n",
    "\n",
    "    df = pd.read_csv(os.path.join(dir, file))\n",
    "    cond = conditions[file.split('.')[0]]\n",
    "    if cond == 'skip':\n",
    "        print(f'Skipping {file}')\n",
    "        continue\n",
    "    for col in cols_to_combine:\n",
    "        if cond == 'avg':\n",
    "            df[f'{col}_comb'] = (df[col] + df[f'{col}_b'])/2\n",
    "        elif cond == 'a':\n",
    "            df[f'{col}_comb'] = df[col]\n",
    "        elif cond == \"b\":\n",
    "            df[f'{col}_comb'] = df[f'{col}_b']\n",
    "        else:\n",
    "            raise ValueError(\"cond value not recognized\")\n",
    "\n",
    "    necessary_cols = ['BDDateTime', 'current_temp_f', 'current_humidity', 'current_dewpoint_f', 'pressure', 'pm1_0_atm_comb', 'pm2_5_atm_comb', 'pm10_0_atm_comb', 'pm2_5_cf_1_comb']\n",
    "    df = df[necessary_cols].copy()\n",
    "    target_file_dir = os.path.join(target, file)\n",
    "    df.to_csv(target_file_dir, index=False)\n",
    "    print(\"File saved : \", target_file_dir)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Appling calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calibration\n",
    "## (thersholds were applied once again here)\n",
    "\n",
    "def calibrate_cf_1(time, pm2_5):\n",
    "    if pd.isnull(time) or pd.isnull(pm2_5):\n",
    "        return float('nan')\n",
    "    month = time.month\n",
    "    if month < 4 or month > 9:\n",
    "        res =  0.63*pm2_5 - 1.1\n",
    "    else:\n",
    "        res =  0.77 * pm2_5 + 6.4\n",
    "    \n",
    "    if res >= 5 and res <= 500:\n",
    "        return res\n",
    "    else:\n",
    "        return float('nan')\n",
    "    \n",
    "def calibrate_atm(time, pm2_5):\n",
    "    if pd.isnull(time) or pd.isnull(pm2_5):\n",
    "        return float('nan')\n",
    "    month = time.month\n",
    "    if month < 4 or month > 9:\n",
    "        res =  0.96*pm2_5 - 2.0\n",
    "    else:\n",
    "        res = 1.4 * pm2_5 - 10.23\n",
    "\n",
    "    if res >= 5 and res <= 500:\n",
    "        return res\n",
    "    else:\n",
    "        return float('nan')\n",
    "    \n",
    "def limit_data(time, data):\n",
    "    if pd.isnull(time) or pd.isnull(data):\n",
    "        return float('nan')\n",
    "    if data >= 5 and data <= 500:\n",
    "        return data\n",
    "    else:\n",
    "        return float('nan')    \n",
    "\n",
    "\n",
    "## average calculation\n",
    "dir = \"channel_combined\"\n",
    "target = 'calibrated_2min'\n",
    "files = [f for f in os.listdir(dir) if f.endswith('csv')]\n",
    "for file in tqdm(files):\n",
    "    print(f'processing {file}')\n",
    "        \n",
    "    df = pd.read_csv(os.path.join(dir, file))\n",
    "    df['BDDateTime'] = pd.to_datetime(df['BDDateTime'])\n",
    "\n",
    "    df['pm2_5_cf_1_calibrated'] = df.apply(\n",
    "        lambda row : calibrate_cf_1(row['BDDateTime'], row['pm2_5_cf_1_comb']), axis = 1\n",
    "    )\n",
    "    df['pm2_5_atm_calibrated'] = df.apply(\n",
    "        lambda row : calibrate_atm(row['BDDateTime'], row['pm2_5_atm_comb']), axis = 1\n",
    "    )\n",
    "    df['pm1_0_atm_comb'] = df.apply(\n",
    "        lambda row : limit_data(row['BDDateTime'], row['pm1_0_atm_comb']), axis = 1\n",
    "    )\n",
    "    df['pm10_0_atm_comb'] = df.apply(\n",
    "        lambda row : limit_data(row['BDDateTime'], row['pm10_0_atm_comb']), axis = 1\n",
    "    )\n",
    "\n",
    "    df.loc[(df['pm2_5_atm_calibrated'] <= 0) | (df['pm2_5_atm_calibrated'] > 500), 'pm2_5_atm_calibrated'] = float('nan')\n",
    "    df.loc[(df['pm2_5_cf_1_calibrated'] <= 0) | (df['pm2_5_cf_1_calibrated'] > 500), 'pm2_5_cf_1_calibrated'] = float('nan')\n",
    "\n",
    "    df.drop(columns=['pm2_5_atm_comb', 'pm2_5_cf_1_comb'], inplace=True)\n",
    "    df.rename(columns={\n",
    "        'pm2_5_atm_calibrated' : 'pm2_5_atm',\n",
    "        'pm2_5_cf_1_calibrated' : 'pm2_5_cf_1',\n",
    "        'pm1_0_atm_comb' : 'pm1_0_atm',\n",
    "        'pm10_0_atm_comb' : 'pm10_0_atm'\n",
    "    }, inplace=True)\n",
    "\n",
    "    df.to_csv(os.path.join(target, file), index=False)\n",
    "    print(\"Saved\", file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hourly average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly_averages(df, datas, time='UTCDateTime', name = None):\n",
    "    results = {\"time\" : []}\n",
    "    for col in datas:\n",
    "        results[col] = []\n",
    "    for col in datas:\n",
    "        results[col+\"count\"] = []\n",
    "    \n",
    "\n",
    "    # Ensure the DataFrame has the correct time and data columns\n",
    "    df = df[datas + [time]].copy()\n",
    "    # df = df.dropna()  # Remove rows with NaN in time or data columns\n",
    "    df[time] = pd.to_datetime(df[time])  # Ensure time column is datetime\n",
    "    df = df.sort_values(by=time)  # Sort by time column\n",
    "\n",
    "    # Generate specific hourly times for calculation (00:30, 01:30, ..., 23:30)\n",
    "    start_time = df[time].min().replace(minute=30, second=0, microsecond=0)\n",
    "    end_time = df[time].max().replace(minute=30, second=0, microsecond=0)\n",
    "    hourly_times = pd.date_range(start=start_time, end=end_time, freq=\"1h\")\n",
    "\n",
    "    for target_time in tqdm(hourly_times, desc=f\"Taking hourly averages : {name}\"):\n",
    "        # Append the results\n",
    "        results[\"time\"].append(target_time)\n",
    "        # Define the 1-hour window (30 minutes before and after)\n",
    "        start_window = target_time - pd.Timedelta(minutes=30)\n",
    "        end_window = target_time + pd.Timedelta(minutes=30)\n",
    "        # Filter data within the window\n",
    "        window_data_all = df[(df[time] >= start_window) & (df[time] <= end_window)][datas]\n",
    "        for data in datas:\n",
    "            # Count the number of data points in the window\n",
    "            window_data = window_data_all[data].dropna()\n",
    "            count = len(window_data)\n",
    "            # Compute the average if the number of points is >= 10\n",
    "            if count >= 23:\n",
    "                avg = window_data.mean()\n",
    "            else:\n",
    "                avg = np.nan  # Fill with NaN if insufficient data\n",
    "            \n",
    "            results[data].append(avg)\n",
    "            results[data+'count'].append(count)\n",
    "\n",
    "    # Convert results to a DataFrame for convenience\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly average\n",
    "dir = \"calibrated_2min\"\n",
    "files = [f for f in os.listdir(dir) if f.endswith('.csv')]\n",
    "for file in tqdm(files, desc=\"Processing homes\"):\n",
    "    print('='*50)\n",
    "    print(f\"Processing {file}\")\n",
    "\n",
    "    if False and os.path.exists(os.path.join(dir, subdir, f'Hourly_average_{type}.csv')):\n",
    "        print(\"file found. skipping\")\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(dir, file), parse_dates=['BDDateTime'])\n",
    "    hourly_avg = hourly_averages(df, datas=['current_temp_f', 'current_humidity', 'current_dewpoint_f', 'pressure', \"pm1_0_atm\", 'pm2_5_atm', \"pm10_0_atm\", \"pm2_5_cf_1\"], time='BDDateTime', name = file)\n",
    "    hourly_avg.to_csv(os.path.join('hourly_averages', file), index=False)\n",
    "    print(f\"saved : {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daily Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_averages(df, datas, time='UTCDateTime', name=None):\n",
    "    \"\"\"\n",
    "    Generate daily averages from an hourly-averaged dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing hourly averages with a time column and one column per data in `datas`.\n",
    "    datas : list[str]\n",
    "        Names of the data columns to average daily (same as used in hourly_averages).\n",
    "    time : str, default 'UTCDateTime'\n",
    "        Name of the datetime column.\n",
    "    name : str or None\n",
    "        Optional label for the tqdm progress bar.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with columns:\n",
    "          - 'time' (daily timestamps at 00:00)\n",
    "          - one column per data in `datas` (daily average, NaN if <= 12 hourly points available)\n",
    "          - one '{data}count' column per data with the number of hourly points used that day\n",
    "    \"\"\"\n",
    "    results = {\"time\": []}\n",
    "    for col in datas:\n",
    "        results[col] = []\n",
    "    for col in datas:\n",
    "        results[col + \"count\"] = []\n",
    "\n",
    "    # Ensure time is datetime and sorted\n",
    "    df = df.copy()\n",
    "    df[time] = pd.to_datetime(df[time])\n",
    "    df = df.sort_values(by=time)\n",
    "\n",
    "    # Build daily range from min to max day (normalized to midnight)\n",
    "    start_day = df[time].min().normalize()\n",
    "    end_day = df[time].max().normalize()\n",
    "    daily_days = pd.date_range(start=start_day, end=end_day, freq=\"1D\")\n",
    "\n",
    "    for day in tqdm(daily_days, desc=f\"Taking daily averages : {name}\"):\n",
    "        # Daily window: [00:00, next day 00:00)\n",
    "        start_window = day\n",
    "        end_window = day + pd.Timedelta(days=1)\n",
    "\n",
    "        results[\"time\"].append(day)\n",
    "\n",
    "        window_df = df[(df[time] >= start_window) & (df[time] < end_window)]\n",
    "\n",
    "        for data in datas:\n",
    "            series = window_df[data].dropna()\n",
    "            count = len(series)\n",
    "\n",
    "            # Require > 12 hourly points to compute daily average\n",
    "            if count > 12:\n",
    "                avg = series.mean()\n",
    "            else:\n",
    "                avg = np.nan\n",
    "\n",
    "            results[data].append(avg)\n",
    "            results[data + \"count\"].append(count)\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily average\n",
    "dir = \"hourly_averages\"\n",
    "target = 'daily_averages'\n",
    "files = [d for d in os.listdir(dir) if d.endswith('.csv')]\n",
    "for file in tqdm(files, desc=\"Processing Schools\"):\n",
    "    print('='*50)\n",
    "    print(f\"Processing {file}\")\n",
    "    if False and os.path.exists(os.path.join(dir, subdir, f'Hourly_average_{type}.csv')):\n",
    "        print(\"file found. skipping\")\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(dir, file))\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    daily_avg = daily_averages(df, datas=['current_temp_f', 'current_humidity', 'current_dewpoint_f', 'pressure', \"pm1_0_atm\", 'pm2_5_atm', \"pm10_0_atm\", \"pm2_5_cf_1\"], time='time', name = file)\n",
    "    daily_avg.to_csv(os.path.join(target, file), index=False)\n",
    "    # daily_avg.info()\n",
    "    print(f\"saved : {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Month avergae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_averages(df, datas, time='UTCDateTime', name=None):\n",
    "    \"\"\"\n",
    "    Generate monthly averages from a daily-averaged dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing daily averages with a time column and one column per data in `datas`.\n",
    "    datas : list[str]\n",
    "        Names of the data columns to average monthly (same as used in daily_averages).\n",
    "    time : str, default 'UTCDateTime'\n",
    "        Name of the datetime column.\n",
    "    name : str or None\n",
    "        Optional label for the tqdm progress bar.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with columns:\n",
    "          - 'time' (monthly timestamps at the first day of the month, 00:00)\n",
    "          - one column per data in `datas` (monthly average, None if < 15 days available)\n",
    "          - one '{data}count' column per data with the number of daily points used that month\n",
    "    \"\"\"\n",
    "\n",
    "    results = {\"time\": []}\n",
    "    for col in datas:\n",
    "        results[col] = []\n",
    "    for col in datas:\n",
    "        results[col + \"count\"] = []\n",
    "\n",
    "    # Ensure time is datetime and sorted\n",
    "    df = df.copy()\n",
    "    df[time] = pd.to_datetime(df[time])\n",
    "    df = df.sort_values(by=time)\n",
    "\n",
    "    # Build list of month starts (MS = Month Start)\n",
    "    start_month = df[time].min().to_period('M').to_timestamp(how='start')\n",
    "    end_month = df[time].max().to_period('M').to_timestamp(how='start')\n",
    "    month_starts = pd.date_range(start=start_month, end=end_month, freq='MS')\n",
    "\n",
    "    for ms in tqdm(month_starts, desc=f\"Taking monthly averages : {name}\"):\n",
    "        # Monthly window: [month_start, next_month_start)\n",
    "        next_ms = (ms + pd.offsets.MonthBegin(1))\n",
    "        window_df = df[(df[time] >= ms) & (df[time] < next_ms)]\n",
    "\n",
    "        results[\"time\"].append(ms)\n",
    "\n",
    "        for data in datas:\n",
    "            series = window_df[data].dropna()\n",
    "            count = int(series.shape[0])\n",
    "\n",
    "            # Require at least 15 daily points to compute monthly average\n",
    "            if count >= 15:\n",
    "                avg = float(series.mean())\n",
    "            else:\n",
    "                avg = None  # keep null if insufficient data\n",
    "\n",
    "            results[data].append(avg)\n",
    "            results[data + \"count\"].append(count)\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly average\n",
    "dir = \"daily_averages\"\n",
    "target = 'monthly_averages'\n",
    "files = [d for d in os.listdir(dir) if d.endswith('.csv')]\n",
    "for file in tqdm(files, desc=\"Processing Schools\"):\n",
    "    print('='*50)\n",
    "    print(f\"Processing {file}\")\n",
    "    if False and os.path.exists(os.path.join(dir, subdir, f'Hourly_average_{type}.csv')):\n",
    "        print(\"file found. skipping\")\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(dir, file))\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    monthly_avg = monthly_averages(df, datas=['current_temp_f', 'current_humidity', 'current_dewpoint_f', 'pressure', \"pm1_0_atm\", 'pm2_5_atm', \"pm10_0_atm\", \"pm2_5_cf_1\"], time='time', name = file)\n",
    "    monthly_avg.to_csv(os.path.join(target, file), index=False)\n",
    "    # monthly_avg.info()\n",
    "    print(f\"saved : {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yearly Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yearly_averages(df, datas, time='UTCDateTime', name=None):\n",
    "    \"\"\"\n",
    "    Generate fiscal-year (Jul 1 → Jun 30) averages from a monthly-averaged dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing monthly averages with a time column and one column per data in `datas`.\n",
    "    datas : list[str]\n",
    "        Names of the data columns to average yearly (same as used in monthly_averages).\n",
    "    time : str, default 'UTCDateTime'\n",
    "        Name of the datetime column.\n",
    "    name : str or None\n",
    "        Optional label for the tqdm progress bar.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with columns:\n",
    "          - 'time' (fiscal-year start timestamps at July 1st, 00:00)\n",
    "          - one column per data in `datas` (yearly average, None if < 9 monthly points in the fiscal year)\n",
    "          - one '{data}count' column per data with the number of monthly points used that fiscal year\n",
    "    \"\"\"\n",
    "\n",
    "    results = {\"time\": []}\n",
    "    for col in datas:\n",
    "        results[col] = []\n",
    "    for col in datas:\n",
    "        results[col + \"count\"] = []\n",
    "\n",
    "    # Ensure time is datetime and sorted\n",
    "    df = df.copy()\n",
    "    df[time] = pd.to_datetime(df[time])\n",
    "    df = df.sort_values(by=time)\n",
    "\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "    # Helper: map any date to its fiscal-year start (July 1)\n",
    "    def fiscal_start(ts: pd.Timestamp) -> pd.Timestamp:\n",
    "        year = ts.year if ts.month >= 7 else ts.year - 1\n",
    "        return pd.Timestamp(year=year, month=7, day=1)\n",
    "\n",
    "    # Build range of fiscal-year starts from min to max\n",
    "    start_fy = fiscal_start(df[time].min())\n",
    "    end_fy = fiscal_start(df[time].max())\n",
    "    fy_starts = pd.date_range(start=start_fy, end=end_fy, freq='YS-JUL')  # Annual Start in July\n",
    "\n",
    "    # Offset for next fiscal-year start\n",
    "    fy_step = pd.offsets.YearBegin(1, month=7)\n",
    "\n",
    "    for fy in tqdm(fy_starts, desc=f\"Taking yearly (Jul-Jun) averages : {name}\"):\n",
    "        next_fy = fy + fy_step\n",
    "        window_df = df[(df[time] >= fy) & (df[time] < next_fy)]\n",
    "\n",
    "        results[\"time\"].append(fy)\n",
    "\n",
    "        for data in datas:\n",
    "            series = window_df[data].dropna()\n",
    "            count = int(series.shape[0])\n",
    "\n",
    "            # Require at least 9 monthly points (~75%) within the fiscal year\n",
    "            if count >= 6:\n",
    "                avg = float(series.mean())\n",
    "            else:\n",
    "                avg = None  # insufficient data for fiscal year average\n",
    "\n",
    "            results[data].append(avg)\n",
    "            results[data + \"count\"].append(count)\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly average\n",
    "dir = \"monthly_averages\"\n",
    "target = 'yearly_averages'\n",
    "files = [d for d in os.listdir(dir) if d.endswith('.csv')]\n",
    "for file in tqdm(files, desc=\"Processing Schools\"):\n",
    "    print('='*50)\n",
    "    print(f\"Processing {file}\")\n",
    "    if False and os.path.exists(os.path.join(dir, subdir, f'Hourly_average_{type}.csv')):\n",
    "        print(\"file found. skipping\")\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(dir, file))\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    yearly_average = yearly_averages(df, datas=['current_temp_f', 'current_humidity', 'current_dewpoint_f', 'pressure', \"pm1_0_atm\", 'pm2_5_atm', \"pm10_0_atm\", \"pm2_5_cf_1\"], time='time', name = file)\n",
    "    yearly_average.to_csv(os.path.join(target, file), index=False)\n",
    "    # yearly_average.info()\n",
    "    print(f\"saved : {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python (pm)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
